# -*- coding: utf-8 -*-
"""Modul_3_RatingProduct_SortingReviews.ipynb adlı not defterinin kopyası

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IyoQqp9N-ce00rOLI-9OfokVSUGCiCRP

***Rating Product & Sorting Reviews in Amazon***

***İş Problemi:***

Ürün ratinglerini daha doğru hesaplamaya
çalışmak ve ürün yorumlarını daha doğru
sıralamak.

**Veri Seti Hikayesi:**

Amazon ürün verilerini içeren bu veri seti ürün kategorileri ile
çeşitli metadataları içermektedir.
Elektronik kategorisindeki en fazla yorum alan ürünün kullanıcı
puanları ve yorumları vardır.

***Değişkenler:***

* reviewerID – Kullanıcı ID’si 
* asin – Ürün ID’si.
* reviewerName : Kullanıcı Adı 
* reviewText : Yorum
* helpful : Faydalı yorum derecesi
* overall : Ürün rating’i
* summary : İnceleme özeti
* unixReviewTime : İnceleme zamanı 
* reviewTime – İnceleme zamanı  (Raw)
"""

import numpy as np  
import pandas as pd  
import math
import scipy.stats as st
import datetime
from datetime import timedelta

pd.set_option('display.max_columns', None)
pd.set_option('display.expand_frame_repr', False)
pd.set_option('display.float_format', lambda x: '%.5f' % x)

# Veri Setinin Okunması
df = pd.read_csv(r"C:\Users\ASUS\Desktop\DSMLBC-8\WEEK_4\amazon_review_veri\amazon_review.csv")

df.head(3)

df.info()

# Tarih değişkenlerini date formatına getirelim  (unixReviewTime,reviewTime )

def convert_datetime(dataframe, variable):
  dataframe[variable] = pd.to_datetime(df[variable])

convert_datetime(df, "reviewTime")

df.info()

# Gün adlarını eklemek istersek:
# weekday_name = df["reviewTime"].dt.day_name()
# df["reviewTime_WeekdayName"] = pd.DataFrame(weekday_name).rename(columns={"reviewTime":"weekday_name"})

"""***GÖREV - 1***

Average Rating’i güncel yorumlara göre
hesaplayınız ve var olan average rating ile
kıyaslayınız.
"""

# Datasetinde yer alan day_diff değişkeni yorum tarihinden iribaten ölçüm tarihine kadar geçen gün sayısını göstermektedir, kendimiz max tarihe bakarak anlamlı olup olmadığını kontrol edelim:

df["reviewTime"].max()

date_difference = int(df.loc[df["reviewerID"] == "A3SBTW3WS4IQSN", ["day_diff"]].iloc[0,0]) #Burada ilgili kullanıcı için 138 gün önce yorum yaptığı gözükmektedir(day_diff)
date_difference

performans_date = df.loc[df["reviewerID"] == "A3SBTW3WS4IQSN", ["reviewTime"]] + timedelta(days=date_difference) #son yorum tarihini kontrol etmiş olduk.
print(performans_date)

# Yukarıda hesapladığımız max reviewtime '2014-12-07' olduğuna göre bu kontrol sonucu çıkan performans tarihi de uyumlu olduğundan veri setindeki day_diff kullanılabilir:

# Yorumun son 30 gün içerisinde yapılmasının kritik olduğunu değerlendirirsek, day_diff değerleri >30 için qcut ile kırılımları oluşturalım:
df_ = df[df["day_diff"] >30 ]

# import warnings
# warnings.filterwarnings('ignore')
df_["day_diff_cat"]  = pd.qcut(df_['day_diff'], 4, ["1", "2", "3", "4"])

df_[["day_diff_cat","day_diff"]].sort_values("day_diff").head(5)

# Kırılımları bulalım:

time_cat = df_.groupby("day_diff_cat").agg({"day_diff" : ["min", "max"]}) 
time_cat
# yaptığı yorum tarihi 30 günü geçenler arasından yapılmıştır.

# Bu tabloyu mapping tablosu olarak kullanmak ve time based fonksiyonun içerisine bu değerleri threshold olarak yerleştirmek istiyoruz:
# 2.seviye başlığı silmemiz ve reset index formuna getirmemiz gerekir:

time_cat.columns = time_cat.columns.droplevel(0) 
time_cat

time_cat.reset_index(inplace=True)
time_cat

# time_cat[time_cat.index == 0]["min"].iloc[0]
# Bu değerleri eşik değeri olarak belirledik.

time_cat[time_cat.index == 0]["min"].values[0]

time_cat[time_cat.index == 0]

time_cat[time_cat.index == 0]["min"]

time_cat[time_cat.index == 0]["min"].values

time_cat[time_cat.index == 0]["min"].values[0]
#Yukarıdaki işlemler array formunda çıktı verir yani np kütüphanesi burada gerekmektedir.

# tüm thresholdları bir değişkene atayalım: 
min_1 = time_cat[time_cat.index == 0]["min"].values[0]
max_1 = time_cat[time_cat.index == 0]["max"].values[0]

min_2 = time_cat[time_cat.index == 1]["min"].values[0]
max_2 = time_cat[time_cat.index == 1]["max"].values[0]

min_3 = time_cat[time_cat.index == 2]["min"].values[0]
max_3 = time_cat[time_cat.index == 2]["max"].values[0]

min_4 = time_cat[time_cat.index == 3]["min"].values[0]
max_4 = time_cat[time_cat.index == 3]["max"].values[0]

print(min_1)
print(max_1)
print(min_2)
print(max_2)
print(min_3)
print(max_3)
print(min_4)
print(max_4)

# Rating'leri zamana göre ağırlıklandıralım:
# Yakın zamanda yapılan yorumlara daha fazla ağırlık verdik.
def time_based_weighted_average(dataframe, w1=35, w2=25, w3=20, w4=15, w5 = 5):
    rating = df.loc[df["day_diff"] < min_1, "overall"].mean() * w1 / 100  + \
             df.loc[((df["day_diff"] >= min_1) & (df["day_diff"] <= max_1)), "overall"].mean() * w2 / 100 + \
             df.loc[((df["day_diff"] >= min_2) & (df["day_diff"] <= max_2)), "overall"].mean() * w3 / 100 + \
             df.loc[((df["day_diff"] >= min_3) & (df["day_diff"] <= max_3)), "overall"].mean() * w4 / 100 + \
             df.loc[df["day_diff"] >= min_4 , "overall"].mean() * w5 / 100
    return rating

#Zamana göre ağırlıklandırılan rating:

time_based_weighted_average(df)

time_based_weighted_average(df , 25, 23, 20, 18, 14)

# Ort rating:

df["overall"].mean()

"""Zamana göre ağırlıklandırılma yapıldığında, rating'in daha yukarı çekildiği görülmektedir, bunun nedeni daha yakın zamanlarda verilen rating'in daha yüksek olmasından kaynaklanmaktadır"""

# çeyreklik değerleri üzerinden zaman bazlı ortalama ağırlıkların belirlenmesi:
def time_based_weighted_average(dataframe, w1=24, w2=22, w3=20, w4=18, w5=16):
    return dataframe.loc[dataframe["day_diff"] <= dataframe["day_diff"].quantile(0.2), "overall"].mean() * w1 / 100 + \
           dataframe.loc[(dataframe["day_diff"] > dataframe["day_diff"].quantile(0.2)) & (dataframe["day_diff"] <= dataframe["day_diff"].quantile(0.4)), "overall"].mean() * w2 / 100 + \
           dataframe.loc[(dataframe["day_diff"] > dataframe["day_diff"].quantile(0.4)) & (dataframe["day_diff"] <= dataframe["day_diff"].quantile(0.6)), "overall"].mean() * w3 / 100 + \
           dataframe.loc[(dataframe["day_diff"] > dataframe["day_diff"].quantile(0.6)) & (dataframe["day_diff"] <= dataframe["day_diff"].quantile(0.8)), "overall"].mean() * w4 / 100 + \
           dataframe.loc[(dataframe["day_diff"] > dataframe["day_diff"].quantile(0.8)), "overall"].mean() * w5 / 100

time_based_weighted_average(df)

time_based_weighted_average(df, w1=35, w2=25, w3=20, w4=15, w5 = 5)

"""***GÖREV-2***

Ürün için ürün detay sayfasında
görüntülenecek 20 review’i belirleyiniz.
"""

df.head()

df["helpful_no"] = df["total_vote"] - df["helpful_yes"]

# En az 1 yorum verilenleri dikkate alalım:
df = df[df["total_vote"]> 0]

# Çoğunlukla kullanılan bir yöntem olan "Score = (up ratings) − (down ratings)" mantığı hiç down etiketlenmemiş ve  up sayısı 3 olan bir yorumun, 100 up - 5 down 
# etiketlenmiş yorumla kıyaslandığında down almamış yorumun yukarıya çekilmesini sağlar.  Oransal olarak bakıldığında ilk örnekte up oranı %100, 2.örnekte up sayısı 
# çok daha yüksek olmasına rağmen %95 gibi görünmektedir, bu durum yanıltıcı olduğundan "Wilson Lower Bound" methodunu kullanacağız:


def score_up_down_diff(up, down):
    return up - down

# Yukarıdaki yönteme kıyasla daha kabul edilebilir, ancak down edilmemiş yorumları fazla dikkate alan bir yöntem olduğundan ideal yöntem WLB yöntemidir. 
 
def score_average_rating(up, down):
    if up + down == 0:
        return 0
    return up / (up + down)

# score_pos_neg_diff
df["score_pos_neg_diff"] = df.apply(lambda x: score_up_down_diff(x["helpful_yes"], x["helpful_no"]), axis=1)

# score_average_rating
df["score_average_rating"] = df.apply(lambda x: score_average_rating(x["helpful_yes"], x["helpful_no"]), axis=1)

def wilson_lower_bound(up, down, confidence=0.95):

    n = up + down
    if n == 0:
        return 0
    z = st.norm.ppf(1 - (1 - confidence) / 2)
    phat = 1.0 * up / n
    return (phat + z * z / (2 * n) - z * math.sqrt((phat * (1 - phat) + z * z / (4 * n)) / n)) / (1 + z * z / n)

wilson_lower_bound(1952, 68, confidence=0.95)   # -> 0.95 olarak score hesaplanacaktır

# Tüm dataframe'e uygulayalım, itreative bir işlem olacağından apply / lambda kullanacağız:
 
df["wilson_lower_bound"] = df.apply(lambda x: wilson_lower_bound(x["helpful_yes"], x["helpful_no"]), axis=1)

# Ürün detay sayfasında gösterilecek 20 review:

df.sort_values("wilson_lower_bound",ascending=False).head(10)

"""***Örneklere bakalım: ***"""

df[["overall","helpful_yes","helpful_no","total_vote","wilson_lower_bound"]].sort_values(by="wilson_lower_bound",ascending=False).head(20)